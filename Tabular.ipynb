{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tabular.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "i0vy-8SK3dpG",
        "3zgV5A2f22Uj",
        "peST-YuqLC0c",
        "d_k_KfVKLSBY",
        "XJX9mr-mvx5_",
        "N-nfk0oYsi6K",
        "FS0Mq4Ynj2Qr",
        "6BzChTcvmBcB",
        "DrS0-hE2m_Wb",
        "u0Jk9S4Z3_bb",
        "dgXsTa5YGcgf",
        "Y7SBKNOAHiiS"
      ],
      "authorship_tag": "ABX9TyO04Rr53BldRS59q/TO7iVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BHouwens/kitchen_sink/blob/main/Tabular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsZFVM8lyLaQ"
      },
      "source": [
        "# **Tabular Boilerplate Notebook**\n",
        "\n",
        "Tabular modeling takes data in the form of a table (like a spreadsheet or CSV), where the objective is to predict the value in one column based on the values in the other columns. This notebook will serve as a boilerplate handler for tabular data modeling, with sections laid out for each major step of the modeling process.\n",
        "\n",
        "**REMEMBER**: This boilerplate is just that: boilerplate! It's a good idea to perform your own exploration in a manner that's specific to your given dataset. The default boilerplate uses the Titanic dataset from Kaggle as an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ergFQr03aV"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "This is the section for setting up your work environment, with boilerplate setups for a number of mainstream options. Don't see one you like? Add your own!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT6eHX-807P3"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjL7RgGWBkFN"
      },
      "source": [
        "### **Imports and Installs**\n",
        "\n",
        "Declare all your project's required imports and installs here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgqMJl4iCF9Z"
      },
      "source": [
        "# Installs\n",
        "!pip install -Uqq fastai waterfallcharts treeinterpreter dtreeviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IJ7L33A6Kk"
      },
      "source": [
        "# Imports\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from dtreeviz.trees import *\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sn\n",
        "from scipy import stats\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdwIw9CLyZcV"
      },
      "source": [
        "# Statsmodels install (only necessary if module is needed and Colab gives trouble)\n",
        "! pip install --upgrade Cython\n",
        "! pip install --upgrade git+https://github.com/statsmodels/statsmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEJMQjpe7eu0"
      },
      "source": [
        "# Set up some constraints here, if desired\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_columns = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhbbdLsE09HL"
      },
      "source": [
        "### **Colab Setup**\n",
        "\n",
        "You can set up the Google Colab environment for data by mounting your Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8P1kCi1HjW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkmSsHkE1WfX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7jfybmzXag"
      },
      "source": [
        "## **Data Collection**\n",
        "\n",
        "Data specific to your current task can be collected here. There'll be different setups depending on where you're running this notebook, but the output here will be used for further data exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7YbEABW7gpz"
      },
      "source": [
        "### **Kaggle Datasets**\n",
        "\n",
        "Get yourself started with some Kaggle datasets. First, set up your API credentials:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svqQ_YRf7dsI"
      },
      "source": [
        "creds = {\"username\":\"USERNAME_HERE\",\"key\":\"API_KEY_HERE\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcsUEi8z8qk9"
      },
      "source": [
        "Then set the credentials up in the `kaggle.json` so that Kaggle knows where to look for them in API calls:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMXu8f9x9QrO"
      },
      "source": [
        "!mkdir .kaggle\n",
        "!mv .kaggle /root/\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "\n",
        "!ls /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw7rlihY_G4O"
      },
      "source": [
        "Then write the credentials to `kaggle.json` with the correct permissions setup to enable access to Kaggle datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOPNmRui8iuF"
      },
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(creds, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sey10ADtbEk1"
      },
      "source": [
        "!export KAGGLE_CONFIG_DIR=/root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjg8OoE_QyQ"
      },
      "source": [
        "Before we finally install Kaggle itself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw72jDFhzalE"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from kaggle import api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpYmGvXvAXnG"
      },
      "source": [
        "Now let's fetch our Kaggle data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9jlEVaAbvU"
      },
      "source": [
        "if not os.path.exists('data'):\n",
        "  os.makedirs('data')\n",
        "\n",
        "# Let's get the Titanic dataset\n",
        "api.competition_download_files('titanic', path='data')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"data/titanic.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "os.remove('data/titanic.zip')\n",
        "os.remove('data/gender_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJ63Hi3FF7e"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2faDRQUJQET"
      },
      "source": [
        "Finally, let's set up some variables for taking the data exploration further:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaHFM0AJUkF"
      },
      "source": [
        "path = \"data\"\n",
        "train_data = \"train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvwFXd9l2evg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUpbp9L62fxo"
      },
      "source": [
        "## **Exploratory Data Analysis**\n",
        "\n",
        "EDA can be performed here, where you'll find cells for showing batches, as well as utility functions for displaying certain analytics. It also contains headings to prompt some thinking about possible exploratory approaches. For tabular data in particular, this section will include tree classifiers for model/data fit inspection.\n",
        "\n",
        "**REMEMBER**: This section is not prescriptive! Add and remove from it as you want and need to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL4O2UU4It_y"
      },
      "source": [
        "### **Look at the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bq0A2p9I0sE"
      },
      "source": [
        "# Setup the dataset path\n",
        "train_path = \"{b}/{d}\".format(b=path, d=train_data)\n",
        "\n",
        "# And read it in to a df\n",
        "df = pd.read_csv(train_path, low_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK71RgIpuEQQ"
      },
      "source": [
        "# Set a \"reset\" df, in case we want to reset the data \n",
        "reset_df = df.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V6hLmXwJt0c"
      },
      "source": [
        "print(df.columns)\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o1UAx7KidL0"
      },
      "source": [
        "# Some values will be individual specific and not useful in a test environment\n",
        "df.drop(['PassengerId', 'Name', 'Ticket'], inplace=True, axis=1, errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW5CzTPfgqf-"
      },
      "source": [
        "We can a bit of a description of our dataset using `df.describe()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y8cfdMDguon"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVfOZvVdhTY9"
      },
      "source": [
        "We can also view the interactions between all possible feature pairs. This isn't necessarily doable for larger datasets, but for the sake of our example it can be done for all features directly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0DCVnTZhebt"
      },
      "source": [
        "# Create the default pairplot\n",
        "sn.pairplot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM6Nt7wO40r7"
      },
      "source": [
        "We can then set our dependent variable, the one we care about. We can also assign every other feature to an independent variablet set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et2vwa6643uQ"
      },
      "source": [
        "dep_var = \"Survived\"\n",
        "ind_var = [c for c in df.columns if c != dep_var]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9OgAGSQ2eBG"
      },
      "source": [
        "It's always important to take a look at some of the entries themselves so that we can develop a better intuition for what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuSFqdl-2lgF"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh9O8y2vAKS-"
      },
      "source": [
        "We can see `NaN` values, which we'll need to decide how we want to handle, as well as pick out any potentially interesting features based on their values. It may also be useful to pick out \"magic features\", those which have a strong correlation to the target given some relatively simple transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vy-8SK3dpG"
      },
      "source": [
        "### **Handling Dates**\n",
        "\n",
        "Dates often pose a challenge from an encoding point of view. They often have a lot of semantic meaning to us though (did it occur on a weekend? a holiday? etc), so we may want to encode special properties of the dates in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrbCk_Ot34QC"
      },
      "source": [
        "# Example from fast.ai Tabular core\n",
        "date_df = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\n",
        "date_df = add_datepart(date_df, 'date')\n",
        "date_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s81w7Uk44KDR"
      },
      "source": [
        "Further date-related features can be built if there is something specifically relevant to our project. For example, do we care about sales in a specific holiday season, or is a particular virus infection rate seasonal? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zgV5A2f22Uj"
      },
      "source": [
        "### **Handling Rank in Ordinal Columns**\n",
        "\n",
        "Some categorical data will be ranked (*ordinal columns*), and for these features it may be useful to tell Pandas about how these categories are ordered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG1JiA323MZ_"
      },
      "source": [
        "# As an example, let's take the passenger class for the Titanic dataset\n",
        "df['Pclass'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0g3uJUz3edp"
      },
      "source": [
        "# export \n",
        "def define_ordinal_rank(df, col, ranks):\n",
        "  \"\"\"\n",
        "  Defines ordinal ranking of a column in a dataset\n",
        "\n",
        "  Args:\n",
        "    df: DataFrame to define for\n",
        "    col: Column to define for\n",
        "    ranks: An array of the ordinal ranking for col\n",
        "  \"\"\"\n",
        "  df[col] = df[col].astype('category')\n",
        "  df[col].cat.set_categories(ranks, ordered=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gOVhZYt5ZLT"
      },
      "source": [
        "define_ordinal_rank(df, 'Pclass', [1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQZ04LiGwAp4"
      },
      "source": [
        "### **Handling Missing Values**\n",
        "\n",
        "It's extremely common to find missing content in datasets and it's important to decide how to handle these. Some libraries, like fastai, do have built in handlers for this, but may be different from those found in something like Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BQtbwO08Lp-"
      },
      "source": [
        "df = reset_df.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRa4cyGZsQ3x"
      },
      "source": [
        "# We can first find which columns contain NaN values\n",
        "df.columns[df.isna().any()].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqgyjSQ_0ZVZ"
      },
      "source": [
        "We can mark the existence of `NaN` in a row-column pair by creating a new column for each of the columns that contain `NaN`. In each of these new columns, if there was a `NaN` in that row we'll mark it with a 1 and if not we'll mark with a 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okhDnyqX0sEL"
      },
      "source": [
        "# export\n",
        "def mark_nan_cols(df):\n",
        "  \"\"\"\n",
        "  Creates a new column for each NaN column in the df, \n",
        "  marking whether the row contained a NaN or not\n",
        "  \"\"\"\n",
        "  nan_cols = df.columns[df.isna().any()].tolist()\n",
        "\n",
        "  for col in nan_cols:\n",
        "    df[\"{}_NaN\".format(col)] = np.where(df[col].isnull(), 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LykwWmoU1PxU"
      },
      "source": [
        "mark_nan_cols(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1M-1HGwds4"
      },
      "source": [
        "# Fill forward\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOrmauDroPX"
      },
      "source": [
        "# Fill with static value\n",
        "df['Cabin'].fillna(\"D999\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWj-R3vsm8T"
      },
      "source": [
        "# Fill with mode\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OrqyPFYsved"
      },
      "source": [
        "# Fill with median\n",
        "df['Age'].fillna(round(df['Age'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxgMlWXSsCH-"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYbr-w9Wuw9G"
      },
      "source": [
        "# Final check\n",
        "df.columns[df.isna().any()].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peST-YuqLC0c"
      },
      "source": [
        "### **Automated Data Checks and Processing**\n",
        "\n",
        "Some simple checks can be made on the dataset automatically, depending on what it is you're looking for. In addition, certain types of augmentation or processing can be performed on the data in an automated fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_k_KfVKLSBY"
      },
      "source": [
        "#### **Roulette Target**\n",
        "\n",
        "A \"roulette\" occurs when there are duplicate rows with different target values. This makes training much more difficult, as target values may be close to random.\n",
        "\n",
        "To start, we'll need to define some kind of acceptable amount of duplicates within the system. This should be generally okay as it's possible that some external, non-codified features have an effect on the target variable. So first we define an acceptable proportion of the dataset as duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyxqmBwlWUTt"
      },
      "source": [
        "ACCEPTANCE_THRES = .02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjjf_aa2s2ny"
      },
      "source": [
        "And then we have two options. One is to do a simple check on the proportion of duplicates in the dataset and match it against our accepted proportion threshold. We do not consider rows that are full duplicates (that is they duplicate both the row values and the targets) so let's first set up a function to find the relevant duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKT6HfsgwsSg"
      },
      "source": [
        "# export\n",
        "def get_relevant_duplicates(df, dep_var):\n",
        "  \"\"\"\n",
        "  Gets number of duplicates with differing targets\n",
        "  \"\"\"\n",
        "  ind_var = [c for c in df.columns if c != dep_var]\n",
        "\n",
        "  # We need to sift out full duplicate rows\n",
        "  poss_dups = df.duplicated(ind_var).sum()\n",
        "  full_dups = df.duplicated().sum()\n",
        "  return poss_dups - full_dups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSuiBMbw0Ng"
      },
      "source": [
        "And then we can implement our simple solution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skYjN6crmkI"
      },
      "source": [
        "# Naive, workable solution\n",
        "relevant_dups = get_relevant_duplicates(df, dep_var)\n",
        "is_roulette = (relevant_dups / len(df) * 100) > ACCEPTANCE_THRES\n",
        "\n",
        "print(\"Dataset is a roulette:\", is_roulette)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpyNZyBWWiMG"
      },
      "source": [
        "This approach can work. A more rigorous approach is to apply a statistical hypothesis test against the accepted threshold and see if that holds up!\n",
        "\n",
        "For this simple test we claim that the dataset is not a roulette ($H_0$) and perform a [1-proportion test](https://www.tutorialspoint.com/statistics/one_proportion_z_test.htm) to find the associated p-value for this hypothesis. Our alternative hypothesis is that our dataset contains fewer relevant duplicates than our accepted threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpWg01prQHxG"
      },
      "source": [
        "# export\n",
        "import statsmodels.api as sm\n",
        "\n",
        "ALPHA = .05\n",
        "\n",
        "def roulette_test(df, dep_var, threshold):\n",
        "  \"\"\"\n",
        "  Performs a 1-proportion z-test on df to check for roulette. \n",
        "  Null hypothesis is that the number of duplicates do not \n",
        "  constitute a roulette dataset, in that the number is lower than \n",
        "  the acceptance threshold\n",
        "  \"\"\"\n",
        "  relevant_dups = get_relevant_duplicates(df, dep_var)\n",
        "  if relevant_dups == 0: return False\n",
        "\n",
        "  _, p_val = sm.stats.proportions_ztest(\n",
        "      relevant_dups, len(df), len(df)*threshold, 'smaller')\n",
        "\n",
        "  return p_val > ALPHA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNCCcebvaCSH"
      },
      "source": [
        "is_roulette = roulette_test(df, dep_var, ACCEPTANCE_THRES)\n",
        "print(\"Dataset is a roulette:\", is_roulette)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plpVm3Fpr66f"
      },
      "source": [
        "This check may or may not be relevant depending on the context of the dataset. Consider an actual roulette wheel's results or the results of a series of horse races, which may in fact contain a number of full duplicates that is higher than our threshold. In such a scenario, it would be beneficial to know before pursuing such a data science project further, as the dataset's value entropy may be too high to warrant further work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJX9mr-mvx5_"
      },
      "source": [
        "#### **Highly Correlated Features**\n",
        "\n",
        "Some features within the dataset may be highly correlated, and we may want to check for these and then make some decision about them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgOX6MQfZ9i"
      },
      "source": [
        "import seaborn as sn\n",
        "\n",
        "corrMatrix = df.corr()\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TBD0vHSe3tF"
      },
      "source": [
        "### **Feature Engineering**\n",
        "\n",
        "Here we can do some feature engineering in order to improve the model's eventual understanding of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmKjU3m8kCNM"
      },
      "source": [
        "# We can start by creating some interactions\n",
        "df['Age_Fare'] = df.apply(lambda row: row.Age * row.Fare, axis=1)\n",
        "df['Age_Fare']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1PIy5zNn8kA"
      },
      "source": [
        "We may also need to specify interesting interactions based on the specifics of our datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Q3yknzoCaU"
      },
      "source": [
        "def is_female_and_high_class(row):\n",
        "  if row.Sex == \"female\" and row.Pclass > 2:\n",
        "    return 1\n",
        "  return 0\n",
        " \n",
        "df['Fem_HC'] = df.apply(is_female_and_high_class, axis=1)\n",
        "df['Fem_HC'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEibOam1BKdC"
      },
      "source": [
        "def has_no_cabin_and_male(row):\n",
        "  if row.Sex == \"male\" and row.Cabin_NaN == 1:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "df['Mal_CNaN'] = df.apply(has_no_cabin_and_male, axis=1)\n",
        "df['Mal_CNaN'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-nfk0oYsi6K"
      },
      "source": [
        "#### **Target Encoding**\n",
        "\n",
        "We can also do some target encoding for categorical inputs. This won't always be a worthwhile approach, but it's worth trying out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdfAnlR8ssgM"
      },
      "source": [
        "def target_encoding(df, feature, target=dep_var, agg_functions={\"mean\",\"std\"}):\n",
        "    agg=df.groupby(feature)[target].agg(agg_functions)\n",
        "    agg.columns=[column+\"_per_{}_{}\".format(feature,target) for column in agg.columns.tolist()]\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CThl3U_RtEA_"
      },
      "source": [
        "This is only useful if we use a subset of the training set to try and encode features, because if we try to use the entire training set we will introduce massive data leakage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYwXfbwhtG3Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, random_state=42, test_size=.2)\n",
        "train_VTE, val_VTE = train_test_split(train,random_state=42,test_size=0.1)\n",
        "test_VTE = test.copy(deep=True)\n",
        "\n",
        "categorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Age_NaN', 'Cabin_NaN', 'Fem_HC']\n",
        "\n",
        "def add_target_encoding_features_validation(train, val, test):\n",
        "    for feature in categorical_features: \n",
        "        agg = target_encoding(train, feature)\n",
        "        train = train.merge(agg, how=\"left\", on=feature)\n",
        "        val = val.merge(agg, how=\"left\", on=feature)\n",
        "        test = test.merge(agg, how=\"left\", on=feature)\n",
        "        \n",
        "    return train, val, test\n",
        "\n",
        "train_VTE, val_VTE, test_VTE = add_target_encoding_features_validation(train_VTE, val_VTE, test_VTE)\n",
        "\n",
        "df = pd.concat([train_VTE, val_VTE, test_VTE])\n",
        "df.reset_index(inplace=True)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz0Bep8PdU2P"
      },
      "source": [
        "\n",
        "### **Basic Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS0Mq4Ynj2Qr"
      },
      "source": [
        "#### **Removing Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f7t11wxj-Y8"
      },
      "source": [
        "# export\n",
        "def remove_outliers(df, cols=None):\n",
        "  \"\"\"\n",
        "  Removes outlier entries in df \n",
        "  \"\"\"\n",
        "  if cols:\n",
        "    w_df = df[cols]\n",
        "  else:\n",
        "    w_df = df\n",
        "\n",
        "  z_scores = np.abs(stats.zscore(w_df, nan_policy='omit'))\n",
        "\n",
        "  if cols:\n",
        "    df = pd.concat([df, w_df], axis=1)\n",
        "\n",
        "  print('z scores', print(len(np.where(z_scores > 3)[0])))\n",
        "  df = df[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BzChTcvmBcB"
      },
      "source": [
        "#### **Drop Rare Features**\n",
        "\n",
        "Certain features may have too few events to provide any meaningful insight to a model, and we can remove these automatically if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVR3oGxzmNYC"
      },
      "source": [
        "# export\n",
        "def drop_rare_features(df, thres=.9):\n",
        "  \"\"\"\n",
        "  Drops features in the dataset that have \n",
        "  events that are too rare to be statistically useful\n",
        "  \"\"\"\n",
        "  rare_f = []\n",
        "  print(\"Running with threshold\", thres)\n",
        "  print(\"\")\n",
        "\n",
        "  for col in df.columns:\n",
        "    if df[col].name not in df.select_dtypes(include='category').columns:\n",
        "      freq = df[col].value_counts(normalize=True)\n",
        "      sum_freq = df[col].sum()\n",
        "              \n",
        "      # should be enough to check whether the most freq is dominant\n",
        "      if freq.iloc[0] >= thres:\n",
        "        rare_f.append(col)\n",
        "        print(\"\\x1b[31m{c}: {v}\\x1b[0m\".format(c=col, v=freq.iloc[0]))\n",
        "      else:\n",
        "        print(\"{c}: {v}\".format(c=col, v=freq.iloc[0]))\n",
        "  \n",
        "  df = df.drop(rare_f, axis=1)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrS0-hE2m_Wb"
      },
      "source": [
        "#### **Final Clean Up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vrvTiiAuTzP"
      },
      "source": [
        "# Remove outliers\n",
        "print(\"DF before:\", df.shape)\n",
        "print(\"\")\n",
        "\n",
        "df = remove_outliers(df, ['Age_Fare','Fare'])\n",
        "\n",
        "print(\"\")\n",
        "print(\"DF after removing outliers\", df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHQlGG2rnG-o"
      },
      "source": [
        "# Drop rare features\n",
        "print(\"DF before:\", len(df.columns))\n",
        "print(\"\")\n",
        "\n",
        "df = drop_rare_features(df)\n",
        "\n",
        "print(\"\")\n",
        "print(\"DF after drop rare features:\", len(df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqUimg7dYD_"
      },
      "source": [
        "print(\"DF before:\", len(df))\n",
        "\n",
        "ind_vars = [c for c in df.columns if c != dep_var]\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(subset=ind_vars, inplace=True)\n",
        "print(\"DF after drop duplicates:\", len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOAKRMlY7UgR"
      },
      "source": [
        "df.drop(['index', 'Ticket'], inplace=True, axis=1, errors=\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8GM0jhtFNXw"
      },
      "source": [
        "### **Conversion to TabularPandas**\n",
        "\n",
        "If we want to convert our dataset into a `TabularPandas` dataset from [fast.ai](https://docs.fast.ai/tabular.core.html#TabularPandas) we can do so here, specifying all the preprocessing and splitting we'd require."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY7uAAR_Har0"
      },
      "source": [
        "# Start by defining procs\n",
        "procs = [Categorify, Normalize]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9gGiNhFxiO"
      },
      "source": [
        "#### **Splitting**\n",
        "\n",
        "If we have timeseries data we'll probably want to manually specify a validation set, as the sequential nature may be important to the understanding of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv55ZkhdF_H5"
      },
      "source": [
        "# Example splitting for timeseries\n",
        "cond = (df.saleYear<2011) | (df.saleMonth<10)\n",
        "train_idx = np.where( cond)[0]\n",
        "valid_idx = np.where(~cond)[0]\n",
        "\n",
        "splits = (list(train_idx),list(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcZJuvPOHQZU"
      },
      "source": [
        "Alternatively you can split randomly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnADgAkWHSJC"
      },
      "source": [
        "splits = RandomSplitter()(range_of(df))\n",
        "splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayezjCayGI7Q"
      },
      "source": [
        "#### **Final Setup**\n",
        "\n",
        "For categorical data we'll want to tell `TabularPandas` which columns are categorical and which are continuous:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJk2fu61GO4u"
      },
      "source": [
        "cont,cat = cont_cat_split(df, dep_var=dep_var)\n",
        "print(\"Continuous columns:\", cont)\n",
        "print(\"Categorical columns:\", cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3XgTs8HtTX"
      },
      "source": [
        "# Finally we set the TabularPandas df up\n",
        "tdf = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDtS5_suH9xs"
      },
      "source": [
        "tdf.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v22gG_oDIcIw"
      },
      "source": [
        "tdf.items.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcFqbV-GH48g"
      },
      "source": [
        "len(tdf.train),len(tdf.valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWiFq4uyKrVr"
      },
      "source": [
        "We can also now save the data, as we've probably done a lot of work on it up to this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChZrwTMZKynH"
      },
      "source": [
        "save_pickle(\"{}/tdf.pkl\".format(path),tdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecQ0yAjL2zj_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkp4T4fR20X7"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "Model work can be performed here, with utilities to help with cross-validation and architecture construction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuominZJ3bd2"
      },
      "source": [
        "# Let's start by setting up our separate sets\n",
        "train_x, train_y = tdf.train.xs, tdf.train.y\n",
        "valid_x, valid_y = tdf.valid.xs, tdf.valid.y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BDScygR9T8"
      },
      "source": [
        "print(\"First train features:\", train_x.iloc[0])\n",
        "print(\"\")\n",
        "print(\"First train label:\", train_y.iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUem8Cp9Orb7"
      },
      "source": [
        "### **Baseline Tree Model**\n",
        "\n",
        "Tabular data has not been completely dominated by neural nets, and tree models are still a viable option to model such datasets. Even if we do go with a neural net (or some ensemble) for the final model, we can still infer a lot about how a model sees the data by starting with a tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ezujRlQVQA"
      },
      "source": [
        "m = DecisionTreeClassifier(max_leaf_nodes=4)\n",
        "m.fit(train_x, train_y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEVCXHj2QmKk"
      },
      "source": [
        "We can then view the results visually:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB1PW6wASiiB"
      },
      "source": [
        "tree.plot_tree(m, feature_names=train_x.columns, precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK2aOyjCQqCc"
      },
      "source": [
        "# DTreeViz result\n",
        "samp_idx = np.random.permutation(len(train_y))[:500]\n",
        "dtreeviz(m, train_x.iloc[samp_idx], train_y.iloc[samp_idx], train_x.columns, dep_var,\n",
        "        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n",
        "        orientation='LR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7w_lwKvbYxN"
      },
      "source": [
        "m = RandomForestClassifier(n_estimators=50)\n",
        "m.fit(train_x, train_y)\n",
        "\n",
        "preds = m.predict(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot-XqjJEYyOn"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(valid_y, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5E63qaZ19J"
      },
      "source": [
        "# Let's find the reasonable number of trees\n",
        "m = DecisionTreeClassifier()\n",
        "m.fit(train_x, train_y);\n",
        "\n",
        "plt.plot([accuracy_score(m.predict(train_x[:i+1]), valid_y[:i+1]) for i in range(150)]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxL8ipigbx20"
      },
      "source": [
        "### **Tree Variance for Prediction Confidence**\n",
        "\n",
        "How can we know the confidence of our random forest estimates? One simple way is to use the standard deviation of predictions across the trees, instead of just the mean. This tells us the relative confidence of predictions. In general, we would want to be more cautious of using the results for rows where trees give very different results (higher standard deviations), compared to cases where they are more consistent (lower standard deviations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOD7rZ2rcNoz"
      },
      "source": [
        "m = RandomForestClassifier(n_estimators=50)\n",
        "m.fit(train_x, train_y)\n",
        "\n",
        "# Let's get predictions for each tree\n",
        "preds = np.stack([t.predict(valid_x) for t in m.estimators_])\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHPcDEjWcchd"
      },
      "source": [
        "# Now let's look at the standard deviation\n",
        "preds_std = preds.std(0)\n",
        "\n",
        "preds_std[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaq73uZ8cpcL"
      },
      "source": [
        "As you can see, the confidence in the predictions varies widely and it seems like the trees are not able to come to a general consensus. For some passengers, there is a low standard deviation because the trees agree. For others it's higher, as the trees don't agree. This is information that would be useful in a production setting; for instance, if you were using a model to decide what items to bid on at auction, a low-confidence prediction might cause you to look more carefully at an item before you made a bid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-JGK-TmdLt6"
      },
      "source": [
        "### **Feature Importance**\n",
        "\n",
        "It's critical for us to know how the trees are making their decisions, and which features they're leaning on to do so. We can get these directly from `sklearn`'s random forest by looking in the `feature_importances_` attribute. Here's a simple function we can use to pop them into a DataFrame and sort them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGI-niMBdcCs"
      },
      "source": [
        "def rf_feat_importance(m, df):\n",
        "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
        "                       ).sort_values('imp', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqSmUITddhHn"
      },
      "source": [
        "# Let's view the most important features to our model\n",
        "fi = rf_feat_importance(m, train_x)\n",
        "fi[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGXaA-tSdthG"
      },
      "source": [
        "We can also plot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKW2WvvGdvW0"
      },
      "source": [
        "fi[:30].plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjzXAfjwd7L8"
      },
      "source": [
        "We can remove the features that are of very low importance and see if that has any effect on the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo9eB_Q2eAbI"
      },
      "source": [
        "to_keep = fi[fi.imp>0.005].cols\n",
        "list(to_keep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JcM-c6jeNq3"
      },
      "source": [
        "xs_imp = train_x[to_keep]\n",
        "valid_xs_imp = valid_x[to_keep]\n",
        "\n",
        "# Retrain\n",
        "m = RandomForestClassifier(n_estimators=50)\n",
        "m.fit(xs_imp, train_y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqZJgZxGeag2"
      },
      "source": [
        "preds = m.predict(valid_xs_imp)\n",
        "accuracy_score(valid_y, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-QJ6zDz9Oqf"
      },
      "source": [
        "### **Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k2PmwhDTZ6e"
      },
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36BDQAxxTsF8"
      },
      "source": [
        "dls.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcMvXu5D9QxS"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "dls = tdf.dataloaders()\n",
        "learn = tabular_learner(dls, metrics=accuracy, loss_func=F.cross_entropy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6IrM8zJIdJQ"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylRZIxyMBSC"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T4rpHgwOtWU"
      },
      "source": [
        "preds,targs = learn.get_preds()\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0-VLja4I04"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Jk9S4Z3_bb"
      },
      "source": [
        "## **Inference and Deployment**\n",
        "\n",
        "Here the model can finally be put to use, as well as exported for deployment in an external application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh-UvXAH4HnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQLkb8qoGypR"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgXsTa5YGcgf"
      },
      "source": [
        "## **Exports and Clean Up**\n",
        "\n",
        "Here you can export any cells with the `#export` comment using `notebook2script.py`, as well as cleaning up any environmental changes such as data downloads to a cloud drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7SBKNOAHiiS"
      },
      "source": [
        "### **Exports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2HHwrCEHlH2"
      },
      "source": [
        "!python notebook2script.py Tabular.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_eeNuu-HgVS"
      },
      "source": [
        "### **Clean Up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So--wngFGq9W"
      },
      "source": [
        "# Tear down the data folder\n",
        "!rm -rf data\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}