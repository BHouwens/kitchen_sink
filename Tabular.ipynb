{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tabular.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A7ergFQr03aV",
        "U7YbEABW7gpz",
        "YL4O2UU4It_y",
        "i0vy-8SK3dpG",
        "3zgV5A2f22Uj",
        "nQZ04LiGwAp4",
        "d_k_KfVKLSBY",
        "Qz0Bep8PdU2P",
        "FS0Mq4Ynj2Qr",
        "6BzChTcvmBcB",
        "DrS0-hE2m_Wb",
        "fM9gGiNhFxiO",
        "u0Jk9S4Z3_bb",
        "dgXsTa5YGcgf",
        "Y7SBKNOAHiiS"
      ],
      "authorship_tag": "ABX9TyMxHFcIXU8Ftzqzl0EldThR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsZFVM8lyLaQ"
      },
      "source": [
        "# **Tabular Boilerplate Notebook**\n",
        "\n",
        "Tabular modeling takes data in the form of a table (like a spreadsheet or CSV), where the objective is to predict the value in one column based on the values in the other columns. This notebook will serve as a boilerplate handler for tabular data modeling, with sections laid out for each major step of the modeling process.\n",
        "\n",
        "**REMEMBER**: This boilerplate is just that: boilerplate! It's a good idea to perform your own exploration in a manner that's specific to your given dataset. The default boilerplate uses the Titanic dataset from Kaggle as an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ergFQr03aV"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "This is the section for setting up your work environment, with boilerplate setups for a number of mainstream options. Don't see one you like? Add your own!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT6eHX-807P3"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjL7RgGWBkFN"
      },
      "source": [
        "### **Imports and Installs**\n",
        "\n",
        "Declare all your project's required imports and installs here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgqMJl4iCF9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be430c3e-fd9e-43d8-a364-7891c1070925"
      },
      "source": [
        "# Installs\n",
        "!pip install -Uqq fastai waterfallcharts treeinterpreter dtreeviz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 204kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25h  Building wheel for waterfallcharts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dtreeviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IJ7L33A6Kk"
      },
      "source": [
        "# Imports\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from dtreeviz.trees import *\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import stats"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdwIw9CLyZcV"
      },
      "source": [
        "# Statsmodels install (only necessary if module is needed and Colab gives trouble)\n",
        "! pip install --upgrade Cython\n",
        "! pip install --upgrade git+https://github.com/statsmodels/statsmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEJMQjpe7eu0"
      },
      "source": [
        "# Set up some constraints here, if desired\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_columns = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhbbdLsE09HL"
      },
      "source": [
        "### **Colab Setup**\n",
        "\n",
        "You can set up the Google Colab environment for data by mounting your Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8P1kCi1HjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a35843-7d96-4c00-8be2-df5edad17cc0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkmSsHkE1WfX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7jfybmzXag"
      },
      "source": [
        "## **Data Collection**\n",
        "\n",
        "Data specific to your current task can be collected here. There'll be different setups depending on where you're running this notebook, but the output here will be used for further data exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7YbEABW7gpz"
      },
      "source": [
        "### **Kaggle Datasets**\n",
        "\n",
        "Get yourself started with some Kaggle datasets. First, set up your API credentials:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svqQ_YRf7dsI"
      },
      "source": [
        "creds = {\"username\":\"USERNAME_HERE\",\"key\":\"API_KEY_HERE\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcsUEi8z8qk9"
      },
      "source": [
        "Then set the credentials up in the `kaggle.json` so that Kaggle knows where to look for them in API calls:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMXu8f9x9QrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15607aec-c582-41d2-c9ee-c58abea7275c"
      },
      "source": [
        "!mkdir .kaggle\n",
        "!mv .kaggle /root/\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "\n",
        "!ls /root/.kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw7rlihY_G4O"
      },
      "source": [
        "Then write the credentials to `kaggle.json` with the correct permissions setup to enable access to Kaggle datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOPNmRui8iuF"
      },
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(creds, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sey10ADtbEk1"
      },
      "source": [
        "!export KAGGLE_CONFIG_DIR=/root/.kaggle/kaggle.json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjg8OoE_QyQ"
      },
      "source": [
        "Before we finally install Kaggle itself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw72jDFhzalE"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from kaggle import api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpYmGvXvAXnG"
      },
      "source": [
        "Now let's fetch our Kaggle data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9jlEVaAbvU"
      },
      "source": [
        "if not os.path.exists('data'):\n",
        "  os.makedirs('data')\n",
        "\n",
        "# Let's get the Titanic dataset\n",
        "api.competition_download_files('titanic', path='data')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"data/titanic.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "os.remove('data/titanic.zip')\n",
        "os.remove('data/gender_submission.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAJ63Hi3FF7e",
        "outputId": "b0b65b0b-bdd1-44a0-b190-aa8ea6b251d1"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2faDRQUJQET"
      },
      "source": [
        "Finally, let's set up some variables for taking the data exploration further:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaHFM0AJUkF"
      },
      "source": [
        "path = \"data\"\n",
        "train_data = \"train.csv\""
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvwFXd9l2evg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUpbp9L62fxo"
      },
      "source": [
        "## **Exploratory Data Analysis**\n",
        "\n",
        "EDA can be performed here, where you'll find cells for showing batches, as well as utility functions for displaying certain analytics. It also contains headings to prompt some thinking about possible exploratory approaches. For tabular data in particular, this section will include tree classifiers for model/data fit inspection.\n",
        "\n",
        "**REMEMBER**: This section is not prescriptive! Add and remove from it as you want and need to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL4O2UU4It_y"
      },
      "source": [
        "### **Look at the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bq0A2p9I0sE"
      },
      "source": [
        "# Setup the dataset path\n",
        "train_path = \"{b}/{d}\".format(b=path, d=train_data)\n",
        "\n",
        "# And read it in to a df\n",
        "df = pd.read_csv(train_path, low_memory=False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK71RgIpuEQQ"
      },
      "source": [
        "# Set a \"reset\" df, in case we want to reset the data \n",
        "reset_df = df.copy(deep=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V6hLmXwJt0c",
        "outputId": "28a4fe01-e8ac-4c42-a167-17469e032bfd"
      },
      "source": [
        "print(df.columns)\n",
        "len(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM6Nt7wO40r7"
      },
      "source": [
        "We can then set our dependent variable, the one we care about. We can also assign every other feature to an independent variablet set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et2vwa6643uQ"
      },
      "source": [
        "dep_var = \"Survived\"\n",
        "ind_var = [c for c in df.columns if c != dep_var]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9OgAGSQ2eBG"
      },
      "source": [
        "It's always important to take a look at some of the entries themselves so that we can develop a better intuition for what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "OuSFqdl-2lgF",
        "outputId": "a8c6e543-a31b-40bb-df73-0f20e9e15444"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "5            6         0       3  ...   8.4583   NaN         Q\n",
              "6            7         0       1  ...  51.8625   E46         S\n",
              "7            8         0       3  ...  21.0750   NaN         S\n",
              "8            9         1       3  ...  11.1333   NaN         S\n",
              "9           10         1       2  ...  30.0708   NaN         C\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh9O8y2vAKS-"
      },
      "source": [
        "We can see `NaN` values, which we'll need to decide how we want to handle, as well as pick out any potentially interesting features based on their values. It may also be useful to pick out \"magic features\", those which have a strong correlation to the target given some relatively simple transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vy-8SK3dpG"
      },
      "source": [
        "### **Handling Dates**\n",
        "\n",
        "Dates often pose a challenge from an encoding point of view. They often have a lot of semantic meaning to us though (did it occur on a weekend? a holiday? etc), so we may want to encode special properties of the dates in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "RrbCk_Ot34QC",
        "outputId": "d608457a-59c1-4be5-c788-0b0ef4e97066"
      },
      "source": [
        "# Example from fast.ai Tabular core\n",
        "date_df = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\n",
        "date_df = add_datepart(date_df, 'date')\n",
        "date_df.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Week</th>\n",
              "      <th>Day</th>\n",
              "      <th>Dayofweek</th>\n",
              "      <th>Dayofyear</th>\n",
              "      <th>Is_month_end</th>\n",
              "      <th>Is_month_start</th>\n",
              "      <th>Is_quarter_end</th>\n",
              "      <th>Is_quarter_start</th>\n",
              "      <th>Is_year_end</th>\n",
              "      <th>Is_year_start</th>\n",
              "      <th>Elapsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.575418e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.573776e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.571875e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Year  Month  Week  ...  Is_year_end  Is_year_start       Elapsed\n",
              "0  2019.0   12.0  49.0  ...        False          False  1.575418e+09\n",
              "1     NaN    NaN   NaN  ...        False          False           NaN\n",
              "2  2019.0   11.0  46.0  ...        False          False  1.573776e+09\n",
              "3  2019.0   10.0  43.0  ...        False          False  1.571875e+09\n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s81w7Uk44KDR"
      },
      "source": [
        "Further date-related features can be built if there is something specifically relevant to our project. For example, do we care about sales in a specific holiday season, or is a particular virus infection rate seasonal? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zgV5A2f22Uj"
      },
      "source": [
        "### **Handling Rank in Ordinal Columns**\n",
        "\n",
        "Some categorical data will be ranked (*ordinal columns*), and for these features it may be useful to tell Pandas about how these categories are ordered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG1JiA323MZ_",
        "outputId": "2b5fb7fb-eaad-40f7-b9c1-ca75222d551f"
      },
      "source": [
        "# As an example, let's take the passenger class for the Titanic dataset\n",
        "df['Pclass'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0g3uJUz3edp"
      },
      "source": [
        "# export \n",
        "def define_ordinal_rank(df, col, ranks):\n",
        "  \"\"\"\n",
        "  Defines ordinal ranking of a column in a dataset\n",
        "\n",
        "  Args:\n",
        "    df: DataFrame to define for\n",
        "    col: Column to define for\n",
        "    ranks: An array of the ordinal ranking for col\n",
        "  \"\"\"\n",
        "  df[col] = df[col].astype('category')\n",
        "  df[col].cat.set_categories(ranks, ordered=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gOVhZYt5ZLT"
      },
      "source": [
        "define_ordinal_rank(df, 'Pclass', [1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQZ04LiGwAp4"
      },
      "source": [
        "### **Handling Missing Values**\n",
        "\n",
        "It's extremely common to find missing content in datasets and it's important to decide how to handle these. Some libraries, like fastai, do have built in handlers for this, but may be different from those found in something like Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BQtbwO08Lp-"
      },
      "source": [
        "df = reset_df.copy(deep=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRa4cyGZsQ3x",
        "outputId": "53a37315-7396-4ce0-c3e2-9cc734c7130e"
      },
      "source": [
        "# We can first find which columns contain NaN values\n",
        "df.columns[df.isna().any()].tolist()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age', 'Cabin', 'Embarked']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqgyjSQ_0ZVZ"
      },
      "source": [
        "We can mark the existence of `NaN` in a row-column pair by creating a new column for each of the columns that contain `NaN`. In each of these new columns, if there was a `NaN` in that row we'll mark it with a 1 and if not we'll mark with a 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okhDnyqX0sEL"
      },
      "source": [
        "# export\n",
        "def mark_nan_cols(df):\n",
        "  \"\"\"\n",
        "  Creates a new column for each NaN column in the df, \n",
        "  marking whether the row contained a NaN or not\n",
        "  \"\"\"\n",
        "  nan_cols = df.columns[df.isna().any()].tolist()\n",
        "\n",
        "  for col in nan_cols:\n",
        "    df[\"{}_NaN\".format(col)] = np.where(df[col].isnull(), 1, 0)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LykwWmoU1PxU"
      },
      "source": [
        "mark_nan_cols(df)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1M-1HGwds4"
      },
      "source": [
        "# Fill forward\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOrmauDroPX"
      },
      "source": [
        "# Fill with static value\n",
        "df['Cabin'].fillna(\"D999\", inplace=True)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWj-R3vsm8T"
      },
      "source": [
        "# Fill with mode\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OrqyPFYsved"
      },
      "source": [
        "# Fill with median\n",
        "df['Age'].fillna(round(df['Age'].mean()), inplace=True)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "QxgMlWXSsCH-",
        "outputId": "f46a29d7-f929-4265-d1cc-8b91352ab439"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Age_NaN</th>\n",
              "      <th>Cabin_NaN</th>\n",
              "      <th>Embarked_NaN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>D999</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>D999</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>D999</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ... Age_NaN Cabin_NaN  Embarked_NaN\n",
              "0            1         0       3  ...       0         1             0\n",
              "1            2         1       1  ...       0         0             0\n",
              "2            3         1       3  ...       0         1             0\n",
              "3            4         1       1  ...       0         0             0\n",
              "4            5         0       3  ...       0         1             0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYbr-w9Wuw9G",
        "outputId": "3e7b6505-bdcc-4f72-8ab8-96a1aba11c56"
      },
      "source": [
        "# Final check\n",
        "df.columns[df.isna().any()].tolist()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peST-YuqLC0c"
      },
      "source": [
        "### **Automated Data Checks and Processing**\n",
        "\n",
        "Some simple checks can be made on the dataset automatically, depending on what it is you're looking for. In addition, certain types of augmentation or processing can be performed on the data in an automated fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_k_KfVKLSBY"
      },
      "source": [
        "#### **Roulette Target**\n",
        "\n",
        "A \"roulette\" occurs when there are duplicate rows with different target values. This makes training much more difficult, as target values may be close to random.\n",
        "\n",
        "To start, we'll need to define some kind of acceptable amount of duplicates within the system. This should be generally okay as it's possible that some external, non-codified features have an effect on the target variable. So first we define an acceptable proportion of the dataset as duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyxqmBwlWUTt"
      },
      "source": [
        "ACCEPTANCE_THRES = .02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjjf_aa2s2ny"
      },
      "source": [
        "And then we have two options. One is to do a simple check on the proportion of duplicates in the dataset and match it against our accepted proportion threshold. We do not consider rows that are full duplicates (that is they duplicate both the row values and the targets) so let's first set up a function to find the relevant duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKT6HfsgwsSg"
      },
      "source": [
        "# export\n",
        "def get_relevant_duplicates(df, dep_var):\n",
        "  \"\"\"\n",
        "  Gets number of duplicates with differing targets\n",
        "  \"\"\"\n",
        "  ind_var = [c for c in df.columns if c != dep_var]\n",
        "\n",
        "  # We need to sift out full duplicate rows\n",
        "  poss_dups = df.duplicated(ind_var).sum()\n",
        "  full_dups = df.duplicated().sum()\n",
        "  return poss_dups - full_dups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSuiBMbw0Ng"
      },
      "source": [
        "And then we can implement our simple solution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0skYjN6crmkI",
        "outputId": "add46b17-f1f6-4462-c367-4cf3b278c308"
      },
      "source": [
        "# Naive, workable solution\n",
        "relevant_dups = get_relevant_duplicates(df, dep_var)\n",
        "is_roulette = (relevant_dups / len(df) * 100) > ACCEPTANCE_THRES\n",
        "\n",
        "print(\"Dataset is a roulette:\", is_roulette)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset is a roulette: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpyNZyBWWiMG"
      },
      "source": [
        "This approach can work. A more rigorous approach is to apply a statistical hypothesis test against the accepted threshold and see if that holds up!\n",
        "\n",
        "For this simple test we claim that the dataset is not a roulette ($H_0$) and perform a [1-proportion test](https://www.tutorialspoint.com/statistics/one_proportion_z_test.htm) to find the associated p-value for this hypothesis. Our alternative hypothesis is that our dataset contains fewer relevant duplicates than our accepted threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpWg01prQHxG"
      },
      "source": [
        "# export\n",
        "import statsmodels.api as sm\n",
        "\n",
        "ALPHA = .05\n",
        "\n",
        "def roulette_test(df, dep_var, threshold):\n",
        "  \"\"\"\n",
        "  Performs a 1-proportion z-test on df to check for roulette. \n",
        "  Null hypothesis is that the number of duplicates do not \n",
        "  constitute a roulette dataset, in that the number is lower than \n",
        "  the acceptance threshold\n",
        "  \"\"\"\n",
        "  relevant_dups = get_relevant_duplicates(df, dep_var)\n",
        "  if relevant_dups == 0: return False\n",
        "\n",
        "  _, p_val = sm.stats.proportions_ztest(\n",
        "      relevant_dups, len(df), len(df)*threshold, 'smaller')\n",
        "\n",
        "  return p_val > ALPHA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCCcebvaCSH",
        "outputId": "4b8542e4-787c-40cb-ed0b-81ab8e039517"
      },
      "source": [
        "is_roulette = roulette_test(df, dep_var, ACCEPTANCE_THRES)\n",
        "print(\"Dataset is a roulette:\", is_roulette)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset is a roulette: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plpVm3Fpr66f"
      },
      "source": [
        "This check may or may not be relevant depending on the context of the dataset. Consider an actual roulette wheel's results or the results of a series of horse races, which may in fact contain a number of full duplicates that is higher than our threshold. In such a scenario, it would be beneficial to know before pursuing such a data science project further, as the dataset's value entropy may be too high to warrant further work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJX9mr-mvx5_"
      },
      "source": [
        "#### **Highly Correlated Features**\n",
        "\n",
        "Some features within the dataset may be highly correlated, and we may want to check for these and then make some decision about them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz0Bep8PdU2P"
      },
      "source": [
        "\n",
        "### **Basic Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS0Mq4Ynj2Qr"
      },
      "source": [
        "#### **Removing Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f7t11wxj-Y8"
      },
      "source": [
        "# export\n",
        "def remove_outliers(df, cols=None):\n",
        "  \"\"\"\n",
        "  Removes outlier entries in df \n",
        "  \"\"\"\n",
        "  if cols:\n",
        "    w_df = df[cols]\n",
        "  else:\n",
        "    w_df = df\n",
        "\n",
        "  z_scores = np.abs(stats.zscore(w_df, nan_policy='omit'))\n",
        "\n",
        "  if cols:\n",
        "    df = pd.concat([df, w_df], axis=1)\n",
        "\n",
        "  print('z scores', print(len(np.where(z_scores > 3)[0])))\n",
        "  df = df[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BzChTcvmBcB"
      },
      "source": [
        "#### **Drop Rare Features**\n",
        "\n",
        "Certain features may have too few events to provide any meaningful insight to a model, and we can remove these automatically if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVR3oGxzmNYC"
      },
      "source": [
        "# export\n",
        "def drop_rare_features(df, thres=.9):\n",
        "  \"\"\"\n",
        "  Drops features in the dataset that have \n",
        "  events that are too rare to be statistically useful\n",
        "  \"\"\"\n",
        "  rare_f = []\n",
        "  print(\"Running with threshold\", thres)\n",
        "  print(\"\")\n",
        "\n",
        "  for col in df.columns:\n",
        "    freq = df[col].value_counts(normalize=True)\n",
        "    sum_freq = df[col].sum()\n",
        "            \n",
        "    # should be enough to check whether the most freq is dominant\n",
        "    if freq.iloc[0] >= thres:\n",
        "      rare_f.append(col)\n",
        "      print(\"\\x1b[31m{c}: {v}\\x1b[0m\".format(c=col, v=freq.iloc[0]))\n",
        "    else:\n",
        "      print(\"{c}: {v}\".format(c=col, v=freq.iloc[0]))\n",
        "  \n",
        "  df = df.drop(rare_f, axis=1)\n",
        "  return df"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrS0-hE2m_Wb"
      },
      "source": [
        "#### **Final Clean Up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vrvTiiAuTzP"
      },
      "source": [
        "# Remove outliers\n",
        "print(\"DF before:\", df.shape)\n",
        "print(\"\")\n",
        "\n",
        "df = remove_outliers(df, 'Fare')\n",
        "\n",
        "print(\"\")\n",
        "print(\"DF after removing outliers\", df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQlGG2rnG-o",
        "outputId": "5135dcb9-74b4-40cf-dcf6-ba43570d5c0a"
      },
      "source": [
        "# Drop rare features\n",
        "print(\"DF before:\", len(df.columns))\n",
        "print(\"\")\n",
        "\n",
        "df = drop_rare_features(df)\n",
        "\n",
        "print(\"\")\n",
        "print(\"DF after drop rare features:\", len(df.columns))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DF before: 15\n",
            "\n",
            "Running with threshold 0.9\n",
            "\n",
            "PassengerId: 0.001122334455667789\n",
            "Survived: 0.6161616161616161\n",
            "Pclass: 0.5510662177328844\n",
            "Name: 0.001122334455667789\n",
            "Sex: 0.6475869809203143\n",
            "Age: 0.22671156004489337\n",
            "SibSp: 0.6823793490460157\n",
            "Parch: 0.7609427609427609\n",
            "Ticket: 0.007856341189674524\n",
            "Fare: 0.04826038159371493\n",
            "Cabin: 0.7710437710437711\n",
            "Embarked: 0.7250280583613917\n",
            "Age_NaN: 0.8013468013468014\n",
            "Cabin_NaN: 0.7710437710437711\n",
            "\u001b[31mEmbarked_NaN: 0.9977553310886644\u001b[0m\n",
            "\n",
            "DF after drop rare features 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqUimg7dYD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3ef7a2-52e0-41f5-a295-d0892e1dd079"
      },
      "source": [
        "print(\"DF before:\", len(df))\n",
        "\n",
        "ind_vars = [c for c in df.columns if c != dep_var]\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(subset=ind_vars, inplace=True)\n",
        "print(\"DF after drop duplicates:\", len(df))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DF before: 891\n",
            "DF after drop duplicates: 891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8GM0jhtFNXw"
      },
      "source": [
        "### **Conversion to TabularPandas**\n",
        "\n",
        "If we want to convert our dataset into a `TabularPandas` dataset from [fast.ai](https://docs.fast.ai/tabular.core.html#TabularPandas) we can do so here, specifying all the preprocessing and splitting we'd require."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY7uAAR_Har0"
      },
      "source": [
        "# Start by defining procs\n",
        "procs = [Categorify, Normalize]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9gGiNhFxiO"
      },
      "source": [
        "#### **Splitting**\n",
        "\n",
        "If we have timeseries data we'll probably want to manually specify a validation set, as the sequential nature may be important to the understanding of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv55ZkhdF_H5"
      },
      "source": [
        "# Example splitting for timeseries\n",
        "cond = (df.saleYear<2011) | (df.saleMonth<10)\n",
        "train_idx = np.where( cond)[0]\n",
        "valid_idx = np.where(~cond)[0]\n",
        "\n",
        "splits = (list(train_idx),list(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcZJuvPOHQZU"
      },
      "source": [
        "Alternatively you can split randomly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnADgAkWHSJC"
      },
      "source": [
        "splits = RandomSplitter()(range_of(df))"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayezjCayGI7Q"
      },
      "source": [
        "#### **Final Setup**\n",
        "\n",
        "For categorical data we'll want to tell `TabularPandas` which columns are categorical and which are continuous:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJk2fu61GO4u",
        "outputId": "ef1578c9-088f-4a8a-d25e-abd9d7b12ea3"
      },
      "source": [
        "cont,cat = cont_cat_split(df, dep_var=dep_var)\n",
        "print(\"Continuous columns:\", cont)\n",
        "print(\"Categorical columns:\", cat)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuous columns: ['PassengerId', 'Age', 'Fare']\n",
            "Categorical columns: ['Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Age_NaN', 'Cabin_NaN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3XgTs8HtTX"
      },
      "source": [
        "# Finally we set the TabularPandas df up\n",
        "tdf = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jDtS5_suH9xs",
        "outputId": "080f332c-47e7-43a7-c43a-871dedbd6c2c"
      },
      "source": [
        "tdf.show(5)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Age_NaN</th>\n",
              "      <th>Cabin_NaN</th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>3</td>\n",
              "      <td>Goodwin, Master. William Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>CA 2144</td>\n",
              "      <td>D999</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>46.900002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>151.550003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>3</td>\n",
              "      <td>Naidenoff, Mr. Penko</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349206</td>\n",
              "      <td>D999</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>288.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.895800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mr. Nicholas</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>D999</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123.0</td>\n",
              "      <td>32.5</td>\n",
              "      <td>30.070801</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>1</td>\n",
              "      <td>Daly, Mr. Peter Denis</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113055</td>\n",
              "      <td>E17</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>858.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>26.549999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "v22gG_oDIcIw",
        "outputId": "3112c482-c84b-4559-cc84-5657b89c4ebe"
      },
      "source": [
        "tdf.items.head(5)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Age_NaN</th>\n",
              "      <th>Cabin_NaN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>-1.492656</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.395378</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>567</td>\n",
              "      <td>0.291093</td>\n",
              "      <td>116</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.218335</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.341892</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>38</td>\n",
              "      <td>2.399128</td>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>-0.604032</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>571</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.567639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>354</td>\n",
              "      <td>-0.494595</td>\n",
              "      <td>116</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>-1.247115</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>576</td>\n",
              "      <td>2</td>\n",
              "      <td>0.222475</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>133</td>\n",
              "      <td>-0.047909</td>\n",
              "      <td>116</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>1.617528</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>197</td>\n",
              "      <td>2</td>\n",
              "      <td>1.614582</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>-0.118831</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  Name  ...  Cabin  Embarked  Age_NaN  Cabin_NaN\n",
              "59     -1.492656         0       3   300  ...    116         3        1          2\n",
              "498     0.218335         0       1    19  ...     63         3        1          1\n",
              "287    -0.604032         0       3   571  ...    116         3        1          2\n",
              "122    -1.247115         0       2   576  ...    116         1        1          2\n",
              "857     1.617528         1       1   197  ...    121         3        1          1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcFqbV-GH48g",
        "outputId": "8083fcc6-1e1f-4707-9a01-c6a623ec6ad1"
      },
      "source": [
        "len(tdf.train),len(tdf.valid)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(713, 178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWiFq4uyKrVr"
      },
      "source": [
        "We can also now save the data, as we've probably done a lot of work on it up to this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChZrwTMZKynH"
      },
      "source": [
        "save_pickle(\"{}/tdf.pkl\".format(path),tdf)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecQ0yAjL2zj_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkp4T4fR20X7"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "Model work can be performed here, with utilities to help with cross-validation and architecture construction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuominZJ3bd2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0-VLja4I04"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Jk9S4Z3_bb"
      },
      "source": [
        "## **Inference and Deployment**\n",
        "\n",
        "Here the model can finally be put to use, as well as exported for deployment in an external application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh-UvXAH4HnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQLkb8qoGypR"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgXsTa5YGcgf"
      },
      "source": [
        "## **Exports and Clean Up**\n",
        "\n",
        "Here you can export any cells with the `#export` comment using `notebook2script.py`, as well as cleaning up any environmental changes such as data downloads to a cloud drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7SBKNOAHiiS"
      },
      "source": [
        "### **Exports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2HHwrCEHlH2"
      },
      "source": [
        "!python notebook2script.py Tabular.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_eeNuu-HgVS"
      },
      "source": [
        "### **Clean Up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So--wngFGq9W"
      },
      "source": [
        "# Tear down the data folder\n",
        "!rm -rf data\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}