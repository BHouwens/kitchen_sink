{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQptdH/qaq2aRHAy1bOnCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BHouwens/kitchen_sink/blob/main/NLPPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BjCJfE5s1EX"
      },
      "source": [
        "# **Natural Language Processing (NLP) Prediction**\n",
        "\n",
        "Natural Language Processing (or NLP) modeling takes data in the form of text, where the objective can change depending on what the intent of the model and modeller. This notebook will serve as a boilerplate handler for NLP modeling in prediction, which includes things like predicting sentiment, spam, or things like the author or source website.\n",
        "\n",
        "This notebook will *not* deal with generation tasks, such as generating new content, translation or summarisation. This is left to a separate notebook.\n",
        "\n",
        "..\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**REMEMBER**: This boilerplate is just that: boilerplate! It's a good idea to perform your own exploration in a manner that's specific to your given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUrPXQL6vlps"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "This section will contain everything you need to get set up in your environment, including all imports and installations that you may require for your project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBF3pHHSxrye"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvLLX9YxkZr"
      },
      "source": [
        "# export\n",
        "COLOURS = {\n",
        "    'Reset': \"\\x1b[0m\",\n",
        "    'Bright': \"\\x1b[1m\",\n",
        "    'Dim': \"\\x1b[2m\",\n",
        "    'Underscore': \"\\x1b[4m\",\n",
        "    'Blink': \"\\x1b[5m\",\n",
        "    'Reverse': \"\\x1b[7m\",\n",
        "    'Hidden': \"\\x1b[8m\",\n",
        "    'FgBlack': \"\\x1b[30m\",\n",
        "    'FgRed': \"\\x1b[31m\",\n",
        "    'FgGreen': \"\\x1b[32m\",\n",
        "    'FgYellow': \"\\x1b[33m\",\n",
        "    'FgBlue': \"\\x1b[34m\",\n",
        "    'FgMagenta': \"\\x1b[35m\",\n",
        "    'FgCyan': \"\\x1b[36m\",\n",
        "    'FgWhite': \"\\x1b[37m\",\n",
        "    'BgBlack': \"\\x1b[40m\",\n",
        "    'BgRed': \"\\x1b[41m\",\n",
        "    'BgGreen': \"\\x1b[42m\",\n",
        "    'BgYellow': \"\\x1b[43m\",\n",
        "    'BgBlue': \"\\x1b[44m\",\n",
        "    'BgMagenta': \"\\x1b[45m\",\n",
        "    'BgCyan': \"\\x1b[46m\",\n",
        "    'BgWhite': \"\\x1b[47m\"\n",
        "}\n",
        "\n",
        "def pretty_log(msg, msg_type='info'):\n",
        "  print(\"\")\n",
        "  print(\"{c}//===== {m} =====//{r}\".format(c=COLOURS['FgBlue'], m=msg, r=COLOURS['Reset']))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XraP22c9x5El"
      },
      "source": [
        "### **Imports and Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfKVzuvkvtuR",
        "outputId": "32d255a2-4da4-4cde-f553-fdcb425e0e80"
      },
      "source": [
        "# Installs\n",
        "!pip install -Uqq fastai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 204kB 14.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lhHY03uyDrj"
      },
      "source": [
        "# Imports\n",
        "from fastai.vision.all import *\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIhl3ZDcyXl_"
      },
      "source": [
        "### **Colab Setup**\n",
        "\n",
        "This will get you set up in a Colab environment, with your Google Drive mounted and ready to read and write data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vec1EJuGyjOy"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu4gN0V6yne7"
      },
      "source": [
        "..\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKFHOgYRyvR4"
      },
      "source": [
        "## **Data Collection**\n",
        "\n",
        "This section contains all the code necessary to pull in the relevant data for your project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOQYe4jfy4cq"
      },
      "source": [
        "# FETCH YOUR DATA HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCuQtmi1y8P0"
      },
      "source": [
        "Great! Now that we have our data we can proceed to explore it a little.\n",
        "\n",
        "..\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlTI7OXzFXE"
      },
      "source": [
        "## **Exploratory Data Analysis**\n",
        "\n",
        "EDA can be performed here, where you'll find cells for showing batches, as well as utility functions for displaying certain analytics. It also contains headings to prompt some thinking about possible exploratory approaches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a57qiO0uzOXS"
      },
      "source": [
        "# EXPLORE ALL YOUR FANTASTIC DATA HERE!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ0eu8uezlOi"
      },
      "source": [
        "Now that we've had a chance to explore the data, we can start to preprocess it to get it into a state that's appropriate for our modeling.\n",
        "\n",
        "..\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNZ9Y_PE3Hc4"
      },
      "source": [
        "## **Preprocessing**\n",
        "\n",
        "This section is for preprocessing textual data so that it can be fed into a model. A general approach will involve tokenising the text corpus in some way so that we can more easily prepare it for the model, but there are many ways in which tokenisation can be done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceridqVU3j13"
      },
      "source": [
        "# PERFORM YOUR PREPROCESSING HERE!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPOmPyD_3m8t"
      },
      "source": [
        "Now that the text has been preprocessed we can finally start with our model.\n",
        "\n",
        "..\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A95x2mYuzxtw"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "Model work can be performed here, with utilities to help with cross-validation and architecture construction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9OGUk0mz3sR"
      },
      "source": [
        "# PERFORM MODEL WORK HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuyNOkXz7bN"
      },
      "source": [
        "Great, now that we have a working model we can proceed to export and get ready for implementation in future projects.\n",
        "\n",
        "..\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSkuWrgP0F2M"
      },
      "source": [
        "## **Export and Clean Up**\n",
        "\n",
        "Our model can be exported in this section, as well as any clean up of the environment that we may be running the notebook in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tV9wPhb0U2I"
      },
      "source": [
        "!python notebook2script.py NLPPrediction.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xYJgQhi0Ppi"
      },
      "source": [
        "# Tear down the data folder\n",
        "!rm -rf data\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTBUmBIG0ZDb"
      },
      "source": [
        ".."
      ]
    }
  ]
}